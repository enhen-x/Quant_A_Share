import pandas as pd
import numpy as np
import xgboost as xgb
import os
import joblib
import datetime
from tqdm import tqdm
import sys
import baostock as bs  # å¼•å…¥ baostock è·å–åç§°

# --- å¼•å…¥å…¬å…±ç‰¹å¾åº“ ---
try:
    from src.features_lib import compute_all_features
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from src.features_lib import compute_all_features

# --- è·¯å¾„é…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
RAW_DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'raw')
PROCESSED_DIR = os.path.join(PROJECT_ROOT, 'data', 'processed')
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

# ==========================================
# 0. è·å–å…¨å¸‚åœºè‚¡ç¥¨åç§° (ç”¨äºè¯†åˆ« ST)
# ==========================================
def get_stock_names_map():
    """
    ç™»å½• Baostockï¼Œè·å–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°åç§°
    è¿”å›å­—å…¸: {'sh.600000': 'æµ¦å‘é“¶è¡Œ', ...}
    """
    print("æ­£åœ¨è”ç½‘è·å–æœ€æ–°è‚¡ç¥¨åç§°è¡¨...")
    bs.login()
    
    name_map = {}
    
    # å°è¯•æŸ¥è¯¢æœ€è¿‘ 5 å¤©ï¼Œåªè¦æŸ¥åˆ°æ•°æ®å°±åœæ­¢
    for i in range(5):
        date_chk = (datetime.datetime.now() - datetime.timedelta(days=i)).strftime("%Y-%m-%d")
        rs = bs.query_all_stock(day=date_chk)
        
        data_list = []
        while rs.error_code == '0' and rs.next():
            data_list.append(rs.get_row_data())
            
        if data_list:
            df = pd.DataFrame(data_list, columns=rs.fields)
            name_map = dict(zip(df['code'], df['code_name']))
            print(f"æˆåŠŸè·å–åç§°è¡¨ (æ—¥æœŸ: {date_chk})ï¼Œå…± {len(name_map)} åªã€‚")
            break
            
    bs.logout()
    return name_map

# ==========================================
# 1. è¾…åŠ©æ£€æŸ¥å‡½æ•°
# ==========================================
def check_data_freshness(date_val):
    data_date = pd.to_datetime(date_val).date()
    today = datetime.datetime.now().date()
    delta = (today - data_date).days
    if delta > 3:
        return False, f"æ•°æ®è¿‡æœŸ ({data_date})"
    return True, "æœ€æ–°"

def is_valid_candidate(latest_row, stock_name=""):
    """
    å®ç›˜è¿‡æ»¤å™¨ï¼šå‰”é™¤æ— æ³•äº¤æ˜“çš„è‚¡ç¥¨
    """
    # 1. åç§°æ£€æŸ¥ (æ ¸å¿ƒä¿®å¤ï¼šå‰”é™¤ ST)
    if stock_name:
        upper_name = stock_name.upper()
        if 'ST' in upper_name:
            return False, f"STè‚¡ ({stock_name})"
        if 'é€€' in upper_name:
            return False, f"é€€å¸‚è‚¡ ({stock_name})"
            
    # 2. åœç‰Œ (æˆäº¤é‡ä¸º0)
    if latest_row['volume'] == 0:
        return False, "åœç‰Œ"
    
    # 3. æ¶¨åœ (é˜²æ­¢ä¹°ä¸è¿›)
    if latest_row['pctChg'] > 9.5:
        return False, "å·²æ¶¨åœ"
    
    # 4. è·Œåœ
    if latest_row['pctChg'] < -9.5:
        return False, "å·²è·Œåœ"
    
    # 5. ä»·æ ¼å¼‚å¸¸
    if latest_row['close'] <= 0:
        return False, "ä»·æ ¼å¼‚å¸¸"

    return True, "åˆæ ¼"

# ==========================================
# 2. æ ¸å¿ƒæ‰«æé€»è¾‘
# ==========================================
def run_scanner():
    print("ğŸš€ å¯åŠ¨å®ç›˜é€‰è‚¡æ‰«æå™¨ (ST é˜²å¾¡ç‰ˆ)...")
    
    # 1. å‡†å¤‡å·¥ä½œ
    model_path = os.path.join(MODELS_DIR, 'xgb_alpha_model.json')
    feat_path = os.path.join(MODELS_DIR, 'feature_names.pkl')
    
    if not os.path.exists(model_path):
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼")
        return

    model = xgb.XGBClassifier()
    model.load_model(model_path)
    feature_names = joblib.load(feat_path)
    
    # è·å–åç§°è¡¨
    name_map = get_stock_names_map()
    if not name_map:
        print("âš ï¸ è­¦å‘Šï¼šæ— æ³•è·å–è‚¡ç¥¨åç§°ï¼ŒST è¿‡æ»¤å¯èƒ½å¤±æ•ˆï¼")

    # 2. è¯»å–è‚¡ç¥¨æ± 
    pool_path = os.path.join(PROCESSED_DIR, 'stock_pool.csv')
    stock_pool = pd.read_csv(pool_path)
    target_codes = stock_pool['code'].astype(str).tolist()
    
    scan_results = []
    
    print(f"æ­£åœ¨æ‰«æ {len(target_codes)} åªè‚¡ç¥¨...")
    
    for code in tqdm(target_codes):
        file_path = os.path.join(RAW_DATA_DIR, f"{code}.csv")
        if not os.path.exists(file_path):
            continue
            
        try:
            df = pd.read_csv(file_path)
            if len(df) < 30: continue
            
            # è®¡ç®—ç‰¹å¾
            df = compute_all_features(df)
            latest_row = df.iloc[[-1]].copy()
            
            # è¿‡æ»¤å™¨
            stock_name = name_map.get(code, "")
            valid, reason = is_valid_candidate(latest_row.iloc[0], stock_name)
            if not valid:
                continue

            if latest_row[feature_names].isnull().any().any():
                continue
                
            prob = model.predict_proba(latest_row[feature_names])[0, 1]
            
            scan_results.append({
                'code': code,
                'name': stock_name,
                'date': latest_row['date'].values[0],
                'close': latest_row['close'].values[0],
                'pctChg': latest_row['pctChg'].values[0],
                'probability': prob,
                'bb_width': latest_row['bb_width'].values[0]
            })
            
        except Exception:
            continue

    # 3. è¾“å‡º Top 3
    if scan_results:
        res_df = pd.DataFrame(scan_results)
        
        # å¼ºåˆ¶é€‰ Top 3 (åªè¦æ¦‚ç‡ > 0.5)
        qualified = res_df[res_df['probability'] > 0.5]
        
        if not qualified.empty:
            final_picks = qualified.sort_values(by='probability', ascending=False).head(3)
        else:
            final_picks = res_df.sort_values(by='probability', ascending=False).head(3)
        
        print("\n" + "="*70)
        print(f"ğŸ¯ æœ€ç»ˆé€‰è‚¡ç»“æœ (å·²å‰”é™¤ ST/æ¶¨è·Œåœ)")
        print("="*70)
        
        output_cols = ['code', 'name', 'date', 'close', 'pctChg', 'probability', 'bb_width']
        print(final_picks[output_cols].to_string(index=False))
        
        # --- âœ… ä¿®æ”¹ç‚¹ï¼šæ–‡ä»¶ååŠ ä¸Šæ—¥æœŸ ---
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        file_name = f'buy_list_{today_str}.csv'
        save_path = os.path.join(PROJECT_ROOT, file_name)
        
        final_picks.to_csv(save_path, index=False)
        
        print("\n" + "-"*60)
        print(f"âœ… åŒ…å« ST è¿‡æ»¤çš„æ¸…å•å·²ç”Ÿæˆ: {save_path}")
        print("ğŸ’¡ æœ€åä¸€æ­¥ï¼šè¯·åŠ¡å¿…åœ¨äº¤æ˜“è½¯ä»¶ä¸­å†æ¬¡ç¡®è®¤ K çº¿å½¢æ€ï¼")
        print("-"*60)
        
    else:
        print("æœªæ‰«æåˆ°æœ‰æ•ˆæ•°æ®ã€‚")

if __name__ == "__main__":
    run_scanner()