import pandas as pd
import numpy as np
import xgboost as xgb
import os
import joblib
from sklearn.metrics import precision_score, accuracy_score, classification_report, roc_auc_score

# --- è·¯å¾„é…ç½® ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
PROCESSED_DIR = os.path.join(PROJECT_ROOT, 'data', 'processed')
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

def train_model():
    # 1. è¯»å–æ•°æ®
    data_path = os.path.join(PROCESSED_DIR, 'dataset_labeled.pkl')
    if not os.path.exists(data_path):
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®é›†ï¼Œè¯·å…ˆè¿è¡Œ feature_eng.py å’Œ label_maker.py")
        return

    print("æ­£åœ¨è¯»å–æ•°æ®é›†...")
    df = pd.read_pickle(data_path)
    df = df.sort_values('date').reset_index(drop=True)
    
    # 2. åˆ’åˆ†è®­ç»ƒé›†ä¸éªŒè¯é›†
    split_index = int(len(df) * 0.90)
    train_df = df.iloc[:split_index]
    test_df = df.iloc[split_index:]
    
    print(f"è®­ç»ƒé›†: {len(train_df)} | éªŒè¯é›†: {len(test_df)}")
    print(f"éªŒè¯é›†æ—¶é—´æ®µ: {test_df['date'].min()} è‡³ {test_df['date'].max()}")

    # 3. å‡†å¤‡ç‰¹å¾
    drop_cols = ['code', 'date', 'target', 'future_return', 'excess_return']
    feature_cols = [c for c in df.columns if c not in drop_cols]
    
    X_train = train_df[feature_cols]
    y_train = train_df['target']
    X_test = test_df[feature_cols]
    y_test = test_df['target']
    
    print(f"ä½¿ç”¨ç‰¹å¾ ({len(feature_cols)}ä¸ª): {feature_cols}")

    # ================= ä¿®æ­£é‡ç‚¹ =================
    # 4. é…ç½® XGBoost æ¨¡å‹
    # å°† early_stopping_rounds ç§»åˆ°è¿™é‡Œåˆå§‹åŒ–
    model = xgb.XGBClassifier(
        n_estimators=500,
        learning_rate=0.03,
        max_depth=6,
        min_child_weight=1,
        gamma=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        objective='binary:logistic',
        n_jobs=-1,
        random_state=42,
        eval_metric='auc',
        scale_pos_weight=4.71,  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆæ ¹æ®æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹è°ƒæ•´ï¼‰
        early_stopping_rounds=50  # <--- âœ… ç§»åˆ°è¿™é‡Œï¼
    )

    print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹... (è¯·è€å¿ƒç­‰å¾…)")
    
    # 5. è®­ç»ƒæ¨¡å‹
    # è¿™é‡Œ fit() é‡Œé¢å°±ä¸éœ€è¦å†™ early_stopping_rounds äº†
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_test, y_test)],
        verbose=100  # æ‰“å°é—´éš”
    )
    # ================= ä¿®æ­£ç»“æŸ =================

    # 6. è¯„ä¼°ç»“æœ
    print("\n" + "="*30)
    print("ğŸš€ æ¨¡å‹è¯„ä¼°æŠ¥å‘Š (éªŒè¯é›†)")
    print("="*30)
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    auc = roc_auc_score(y_test, y_pred_proba)
    print(f"AUC å€¼ (æ•´ä½“æ’åºèƒ½åŠ›): {auc:.4f} (è¶Šæ¥è¿‘1è¶Šå¥½ï¼Œ>0.55å³æœ‰æ•ˆ)")
    
    # --- é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ ---
    print("\nğŸ“Š é˜ˆå€¼èƒœç‡åˆ†æ (Precision @ K):")
    print(f"{'é˜ˆå€¼':<10} {'è§¦å‘æ¬¡æ•°':<10} {'çœŸå®èƒœç‡(Precision)':<20} {'æ•è·Alphaæœºä¼š'}")
    print("-" * 60)
    
    for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:
        high_conf_idx = y_pred_proba >= threshold
        count = np.sum(high_conf_idx)
        
        if count > 0:
            real_win_rate = np.mean(y_test[high_conf_idx])
            mark = 'âœ…' if real_win_rate > 0.5 else ''
            print(f"> {threshold:<9} {count:<10} {real_win_rate:.2%}             {mark}")
        else:
            print(f"> {threshold:<9} 0          N/A")

    # 7. ä¿å­˜æ¨¡å‹
    if not os.path.exists(MODELS_DIR):
        os.makedirs(MODELS_DIR)
    
    model_path = os.path.join(MODELS_DIR, 'xgb_alpha_model.json')
    model.save_model(model_path)
    joblib.dump(feature_cols, os.path.join(MODELS_DIR, 'feature_names.pkl'))
    
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    
    # 8. ç‰¹å¾é‡è¦æ€§
    print("\nğŸ† ç‰¹å¾é‡è¦æ€§ Top 10:")
    feature_importances = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values(by='importance', ascending=False)
    print(feature_importances.head(10))

if __name__ == "__main__":
    train_model()